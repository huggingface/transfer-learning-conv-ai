{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "from argparse import ArgumentParser\n",
    "from itertools import chain\n",
    "from pprint import pformat\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import OpenAIGPTLMHeadModel, OpenAIGPTTokenizer, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from train import SPECIAL_TOKENS, build_input_from_segments, add_special_tokens_\n",
    "#from utils import get_dataset, download_pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sequence(personality, history, tokenizer, model, args, current_output=None):\n",
    "    special_tokens_ids = tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS)\n",
    "    if current_output is None:\n",
    "        current_output = []\n",
    "\n",
    "    for i in range(args['max_length']):\n",
    "        instance = build_input_from_segments(personality, history, current_output, tokenizer, with_eos=False)\n",
    "\n",
    "        input_ids = torch.tensor(instance[\"input_ids\"], device=args['device']).unsqueeze(0)\n",
    "        token_type_ids = torch.tensor(instance[\"token_type_ids\"], device=args['device']).unsqueeze(0)\n",
    "\n",
    "        logits = model(input_ids, token_type_ids=token_type_ids)\n",
    "        if isinstance(logits, tuple):  # for gpt2 and maybe others\n",
    "            logits = logits[0]\n",
    "        logits = logits[0, -1, :] / args['temperature']\n",
    "        logits = top_filtering(logits, top_k=args['top_k'], top_p=args['top_p'])\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        prev = torch.topk(probs, 1)[1] if args['no_sample'] else torch.multinomial(probs, 1)\n",
    "        if i < args['min_length'] and prev.item() in special_tokens_ids:\n",
    "            while prev.item() in special_tokens_ids:\n",
    "                if probs.max().item() == 1:\n",
    "                    warnings.warn(\"Warning: model generating special token with probability 1.\")\n",
    "                    break  # avoid infinitely looping over special token\n",
    "                prev = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        if prev.item() in special_tokens_ids:\n",
    "            break\n",
    "        current_output.append(prev.item())\n",
    "\n",
    "    return current_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args['seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_openai:ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-61e8fb079320>\", line 8, in <module>\n",
      "    logger.info(\"Sample a personality\")\n",
      "NameError: name 'logger' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 28, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-61e8fb079320>\", line 8, in <module>\n",
      "    logger.info(\"Sample a personality\")\n",
      "NameError: name 'logger' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "args = {\"min_length\": 1, \"max_length\": 20, \"temperature\":0.7, \"device\":\"cpu\", \"top_k\":0, \"top_p\":0.9, \"seed\":0, \n",
    "        \"model_checkpoint\": \"C:/Users/Bunmi/Desktop/GitHub/transfer-learning-conv-ai/deploy/\"\n",
    "       \"dataset_cache\": \"C:/Users/Bunmi/Desktop/GitHub/transfer-learning-conv-ai/\"}\n",
    "tokenizer_class, model_class = (OpenAIGPTTokenizer, OpenAIGPTLMHeadModel)\n",
    "tokenizer = tokenizer_class.from_pretrained(args['model_checkpoint'])\n",
    "    \n",
    "model = model_class.from_pretrained(args['model_checkpoint'])\n",
    "model.to(\"cpu\")\n",
    "    \n",
    "logger.info(\"Sample a personality\")\n",
    "#dataset = get_dataset(tokenizer, args.dataset_path, args.dataset_cache)\n",
    "#personalities = [dialog[\"personality\"] for dataset in dataset.values() for dialog in dataset]\n",
    "personalities = [\"i like to remodel homes .\", \"i like to go hunting .\",\n",
    "                    \"i like to shoot a bow .\", \"my favorite holiday is halloween .\"]\n",
    "print(personalities)\n",
    "personality = random.choice(personalities)\n",
    "logger.info(\"Selected personality: %s\", tokenizer.decode(chain(*personality)))\n",
    "\n",
    "history = []\n",
    "while True:\n",
    "    raw_text = input(\">>> \")\n",
    "    while not raw_text:\n",
    "        print('Prompt should not be empty!')\n",
    "        raw_text = input(\">>> \")\n",
    "    history.append(tokenizer.encode(raw_text))\n",
    "    with torch.no_grad():\n",
    "        out_ids = sample_sequence(personality, history, tokenizer, model, args)\n",
    "    history.append(out_ids)\n",
    "    history = history[-(2*args.max_history+1):]\n",
    "    out_text = tokenizer.decode(out_ids, skip_special_tokens=True)\n",
    "    print(out_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset, download_pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample a personality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-d722f0c77b60>\", line 5, in <module>\n",
      "    dataset = get_dataset(tokenizer, args['dataset_cache'], args['dataset_cache'])\n",
      "  File \"C:\\Users\\Bunmi\\Desktop\\GitHub\\transfer-learning-conv-ai\\utils.py\", line 41, in get_dataset\n",
      "    with open(personachat_file, \"r\", encoding=\"utf-8\") as f:\n",
      "PermissionError: [Errno 13] Permission denied: 'C:/Users/Bunmi/Desktop/GitHub/transfer-learning-conv-ai/'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'PermissionError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 28, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-d722f0c77b60>\", line 5, in <module>\n",
      "    dataset = get_dataset(tokenizer, args['dataset_cache'], args['dataset_cache'])\n",
      "  File \"C:\\Users\\Bunmi\\Desktop\\GitHub\\transfer-learning-conv-ai\\utils.py\", line 41, in get_dataset\n",
      "    with open(personachat_file, \"r\", encoding=\"utf-8\") as f:\n",
      "PermissionError: [Errno 13] Permission denied: 'C:/Users/Bunmi/Desktop/GitHub/transfer-learning-conv-ai/'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'PermissionError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Bunmi\\OneDrive\\Documents\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/Bunmi/Desktop/GitHub/transfer-learning-conv-ai/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "args = {\"min_length\": 1, \"max_length\": 20, \"temperature\":0.7, \"device\":\"cpu\", \"top_k\":0, \"top_p\":0.9, \"seed\":0, \n",
    "        \"model_checkpoint\": \"C:/Users/Bunmi/Desktop/GitHub/transfer-learning-conv-ai/deploy/\",\n",
    "       \"dataset_cache\": \"C:/Users/Bunmi/Desktop/GitHub/transfer-learning-conv-ai/\"}\n",
    "print(\"Sample a personality\")\n",
    "dataset = get_dataset(tokenizer, args['dataset_cache'], args['dataset_cache'])\n",
    "personalities = [dialog[\"personality\"] for dataset in dataset.values() for dialog in dataset]\n",
    "#personalities = [\"i like to remodel homes .\", \"i like to go hunting .\",\n",
    "#                    \"i like to shoot a bow .\", \"my favorite holiday is halloween .\"]\n",
    "print(personalities)\n",
    "personality = random.choice(personalities)\n",
    "print(\"Selected personality: %s\", tokenizer.decode(chain(*personality)))\n",
    "\n",
    "history = []\n",
    "while True:\n",
    "    raw_text = input(\">>> \")\n",
    "    while not raw_text:\n",
    "        print('Prompt should not be empty!')\n",
    "        raw_text = input(\">>> \")\n",
    "    history.append(tokenizer.encode(raw_text))\n",
    "    with torch.no_grad():\n",
    "        out_ids = sample_sequence(personality, history, tokenizer, model, args)\n",
    "    history.append(out_ids)\n",
    "    history = history[-(2*args.max_history+1):]\n",
    "    out_text = tokenizer.decode(out_ids, skip_special_tokens=True)\n",
    "    print(out_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
