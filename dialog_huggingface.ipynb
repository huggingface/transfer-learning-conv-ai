{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a dialog model using HuggingFace's pytorch-transformers and the ConvAI Dataset \n",
    "\n",
    "### Incorporating migration notes from pytorch_pretrained_bert -> pytorch_transformers\n",
    "Updating the implementations in: https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrequirements.txt: \\ntorch\\npytorch-ignite\\n#pytorch-pretrained-bert >= 0.6.2 -> replaced with pytorch-transformers\\npytorch-transformers\\ntensorboardX\\ntensorflow  # for tensorboardX\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "requirements.txt: \n",
    "torch\n",
    "pytorch-ignite\n",
    "#pytorch-pretrained-bert >= 0.6.2 -> replaced with pytorch-transformers\n",
    "pytorch-transformers\n",
    "tensorboardX\n",
    "tensorflow  # for tensorboardX\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_transformers import OpenAIGPTDoubleHeadsModel, OpenAIGPTTokenizer\n",
    "\n",
    "model = OpenAIGPTDoubleHeadsModel.from_pretrained('openai-gpt')\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of added tokens:  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(40483, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use 5 special tokens:\n",
    "# - <bos> to indicate the start of the sequence\n",
    "# - <eos> to indicate the end of the sequence\n",
    "# - <speaker1> to indicate the beginning and the tokens of an utterance from the user\n",
    "# - <speaker2> to indicate the beginning and the tokens of an utterance from the bot\n",
    "# - <pad> as a padding token to build batches of sequences\n",
    "SPECIAL_TOKENS = {\"bos_token\": \"<bos>\", \n",
    "                  \"eos_token\": \"<eos>\",\n",
    "                  \"speaker1_token\": \"<speaker1>\", \n",
    "                  \"speaker2_token\": \"<speaker2>\",\n",
    "                  \"pad_token\": \"<pad>\"}\n",
    "\n",
    "# We can add these special tokens to the vocabulary and the embeddings of the model:\n",
    "num_added_token = tokenizer.add_special_tokens(SPECIAL_TOKENS)\n",
    "print(\"Number of added tokens: \", num_added_token)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<bos>', '<eos>', '<unk>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<speaker1>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.all_special_tokens)\n",
    "tokenizer.speaker1_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "# Let's define our contexts and special tokens\n",
    "persona = [[\"i\", \"like\", \"playing\", \"football\", \".\"],\n",
    "           [\"i\", \"am\", \"from\", \"NYC\", \".\"]]\n",
    "history = [[\"hello\", \"how\", \"are\", \"you\", \"?\"],\n",
    "           [\"i\", \"am\", \"fine\", \"thanks\", \".\"]]\n",
    "reply = [\"great\", \"to\", \"hear\"]\n",
    "bos, eos, speaker1, speaker2 = \"<bos>\", \"<eos>\", \"<speaker1>\", \"<speaker2>\"\n",
    "\n",
    "def build_inputs(persona, history, reply):\n",
    "    # Build our sequence by adding delimiters and concatenating\n",
    "    sequence = [[bos] + list(chain(*persona))] + history + [reply + [eos]]\n",
    "    sequence = [sequence[0]] + [ [speaker2 if (len(sequence)-i) % 2 else speaker1] + s\n",
    "                                for i, s in enumerate(sequence[1:])]\n",
    "    # Build our word, segments and position inputs from the sequence\n",
    "    words = list(chain(*sequence))                          # word tokens\n",
    "    \n",
    "    ''' fixed i -> i+1 to make it consistent with the labels in `sequence`'''\n",
    "    segments = [speaker2 if (i+1) % 2 else speaker1             # segment tokens\n",
    "                for i, s in enumerate(sequence) for _ in s]\n",
    "    position = list(range(len(words)))                      # position tokens\n",
    "    return words, segments, position, sequence\n",
    "\n",
    "words, segments, position, sequence = build_inputs(persona, history, reply)\n",
    "\n",
    "# >>> print(sequence)  # Our inputs looks like this:\n",
    "# [['<bos>', 'i', 'like', 'playing', 'football', '.', 'i', 'am', 'from', 'NYC', '.'],\n",
    "#  ['<speaker1>', 'hello', 'how', 'are', 'you', '?'],\n",
    "#  ['<speaker2>', 'i', 'am', 'fine', 'thanks', '.'],\n",
    "#  ['<speaker1>', 'great', 'to', 'hear', '<eos>']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words and segments embeddings:\n",
    "words = tokenizer.convert_tokens_to_ids(words)\n",
    "segments = tokenizer.convert_tokens_to_ids(segments)\n",
    "\n",
    "# don't use tokenizer.encode(x) because the sequence is already tokenized. \n",
    "# If given as a string, use tokenizer.encode(x), which is equivalent to tokenizer.convert_tokens_to_ids(tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "distractor = [\"sorry\", \"to\", \"hear\", \"that\"]\n",
    "\n",
    "words_distractor, segments_distractor, _, _ = build_inputs(persona, history, distractor)\n",
    "words_distractor, segments_distractor = tokenizer.convert_tokens_to_ids(words_distractor),  tokenizer.convert_tokens_to_ids(segments_distractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare language modeling targets: keep only the reply segment, -1 on the rest \n",
    "lm_targets = [-1] * sum(len(s) for s in sequence[:-1]) + [-1] + tokenizer.convert_tokens_to_ids(sequence[-1][1:])\n",
    "lm_distractor = [-1]*len(words_distractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_idx = len(words) - 1\n",
    "last_token_distractor = len(words_distractor) -1\n",
    "\n",
    "# pad reply and distractor inputs and targets to same length \n",
    "padding_length = max(len(words), len(words_distractor))\n",
    "\n",
    "def pad(x, padding, padding_length): \n",
    "    return x + [padding] * (padding_length - len(x))\n",
    "\n",
    "words, words_distractor, segments, segments_distractor = [pad(x, tokenizer.convert_tokens_to_ids('<pad>'), padding_length) for x in (words, words_distractor, segments, segments_distractor)]\n",
    "\n",
    "assert len(words) == len(words_distractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_targets, lm_distractor = [pad(x, -1, padding_length) for x in (lm_targets, lm_distractor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([[words, words_distractor]], dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 29])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_type_ids = torch.tensor([[segments, segments_distractor]], dtype=torch.long)\n",
    "mc_token_ids = torch.tensor([[last_token_idx, last_token_distractor]])\n",
    "\n",
    "lm_labels = torch.tensor([[lm_targets, lm_distractor]], dtype=torch.long)\n",
    "mc_labels = torch.tensor([0], dtype=torch.long) # first one is the gold label. Index of first one is 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to change it to new loss return format (comes in tuples, with loss and the prediction logits)\n",
    "lm_loss, mc_loss, lm_predict, mc_predict = model(input_ids, mc_token_ids, lm_labels, mc_labels, token_type_ids) \n",
    "\n",
    "lm_coef = 2.0 \n",
    "mc_coef = 1.0 \n",
    "total_loss = lm_loss*lm_coef + mc_loss*mc_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.2084, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on entire dataset (ConvAI)\n",
    "\n",
    "Original code referenced: [github repo](https://github.com/huggingface/transfer-learning-conv-ai/blob/master/train.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pytorch_transformers import cached_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"s3://datasets.huggingface.co/personachat/personachat_self_original.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/justincho/.cache/torch/pytorch_transformers/738e4d3f264f46d2c9161a43c7389d03a34fb336ae842a4337014123c68e744e.bb42905dd6e1098e87c24845469ee12018cfd142e10fcc50f97b28e002a9ac02\n"
     ]
    }
   ],
   "source": [
    "personachat_file = cached_path(url)\n",
    "with open(personachat_file, \"r\", encoding=\"utf-8\") as f: \n",
    "    dataset = json.load(f)\n",
    "    \n",
    "print(personachat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "personachat = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tokenize_dataset(obj): \n",
    "    if isinstance(obj, str): \n",
    "        return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(obj))\n",
    "    if isinstance(obj, dict): \n",
    "        return {n: tokenize_dataset(o) for n, o in obj.items()}\n",
    "    return list(tokenize_dataset(o) for o in obj)\n",
    "\n",
    "dataset_cache = './dataset_cache'\n",
    "dataset_cache = dataset_cache + '_' + type(tokenizer).__name__\n",
    "\n",
    "if dataset_cache and os.path.isfile(dataset_cache):\n",
    "    dataset = torch.load(dataset_cache)\n",
    "else: \n",
    "    dataset = tokenize_dataset(dataset)\n",
    "    torch.save(dataset, dataset_cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'personality': ['i like to remodel homes .',\n",
       "  'i like to go hunting .',\n",
       "  'i like to shoot a bow .',\n",
       "  'my favorite holiday is halloween .'],\n",
       " 'utterances': [{'candidates': ['my mom was single with 3 boys , so we never left the projects .',\n",
       "    'i try to wear all black every day . it makes me feel comfortable .',\n",
       "    'well nursing stresses you out so i wish luck with sister',\n",
       "    'yeah just want to pick up nba nfl getting old',\n",
       "    'i really like celine dion . what about you ?',\n",
       "    'no . i live near farms .',\n",
       "    \"i wish i had a daughter , i'm a boy mom . they're beautiful boys though still lucky\",\n",
       "    'yeah when i get bored i play gone with the wind my favorite movie .',\n",
       "    \"hi how are you ? i'm eating dinner with my hubby and 2 kids .\",\n",
       "    'were you married to your high school sweetheart ? i was .',\n",
       "    'that is great to hear ! are you a competitive rider ?',\n",
       "    \"hi , i'm doing ok . i'm a banker . how about you ?\",\n",
       "    \"i'm 5 years old\",\n",
       "    'hi there . how are you today ?',\n",
       "    'i totally understand how stressful that can be .',\n",
       "    'yeah sometimes you do not know what you are actually watching',\n",
       "    'mother taught me to cook ! we are looking for an exterminator .',\n",
       "    'i enjoy romantic movie . what is your favorite season ? mine is summer .',\n",
       "    'editing photos takes a lot of work .',\n",
       "    'you must be very fast . hunting is one of my favorite hobbies .'],\n",
       "   'history': [\"hi , how are you doing ? i'm getting ready to do some cheetah chasing to stay in shape .\"]},\n",
       "  {'candidates': ['hello i am doing well how are you ?',\n",
       "    'll something like that . do you play games ?',\n",
       "    'does anything give you relief ? i hate taking medicine for mine .',\n",
       "    'i decorate cakes at a local bakery ! and you ?',\n",
       "    'do you eat lots of meat',\n",
       "    'i am so weird that i like to collect people and cats',\n",
       "    'how are your typing skills ?',\n",
       "    'yeah . i am headed to the gym in a bit to weight lift .',\n",
       "    'yeah you have plenty of time',\n",
       "    'metal is my favorite , but i can accept that people listen to country . haha',\n",
       "    \"that's why you desire to be controlled . let me control you person one .\",\n",
       "    'two dogs they are the best , how about you ?',\n",
       "    'you do art ? what kind of art do you do ?',\n",
       "    'i love watching baseball outdoors on sunny days .',\n",
       "    'oh i see . do you ever think about moving ? i do , it is what i want .',\n",
       "    'sure . i wish it were winter . the sun really hurts my blue eyes .',\n",
       "    'are we pretending to play tennis',\n",
       "    'i am rich and have all of my dreams fulfilled already',\n",
       "    'they tire me so , i probably sleep about 10 hrs a day because of them .',\n",
       "    'i also remodel homes when i am not out bow hunting .'],\n",
       "   'history': [\"hi , how are you doing ? i'm getting ready to do some cheetah chasing to stay in shape .\",\n",
       "    'you must be very fast . hunting is one of my favorite hobbies .',\n",
       "    'i am ! for my hobby i like to do canning or some whittling .']},\n",
       "  {'candidates': ['yes they do but i say no to them lol',\n",
       "    'i have trouble getting along with family .',\n",
       "    'i live in texas , what kind of stuff do you do in toronto ?',\n",
       "    \"that's so unique ! veganism and line dancing usually don't mix !\",\n",
       "    \"no , it isn't that big . do you travel a lot\",\n",
       "    \"that's because they are real ; what do you do for work ?\",\n",
       "    'i am lazy all day lol . my mom wants me to get a job and move out',\n",
       "    'i was born on arbor day , so plant a tree in my name',\n",
       "    'okay , i should not tell you , its against the rules but my name is sarah , call me o',\n",
       "    'hello how are u tonight',\n",
       "    \"cool . . . my parents love country music that's why i hate it\",\n",
       "    'i am an accountant . what do you do ?',\n",
       "    'what do your parents do ? my dad is a mechanic .',\n",
       "    'how are you liking it ?',\n",
       "    'i really am too . great talking to you too .',\n",
       "    'cool . whats it like working there ?',\n",
       "    \"one daughter . she's pre med\",\n",
       "    \"no and all men is taller than me why can't i find a man to dance with\",\n",
       "    'i live in utah , and my family live in england , so i understand',\n",
       "    \"that's awesome . do you have a favorite season or time of year ?\"],\n",
       "   'history': [\"hi , how are you doing ? i'm getting ready to do some cheetah chasing to stay in shape .\",\n",
       "    'you must be very fast . hunting is one of my favorite hobbies .',\n",
       "    'i am ! for my hobby i like to do canning or some whittling .',\n",
       "    'i also remodel homes when i am not out bow hunting .',\n",
       "    \"that's neat . when i was in high school i placed 6th in 100m dash !\"]},\n",
       "  {'candidates': ['not really , it is just a small local radio station . what about you , what do you do ?',\n",
       "    'me too ! people always say i am so organized',\n",
       "    'niagra fall is where our honeymoon will be',\n",
       "    'yes ! i know how to be by myself . you ? i do not need new friends . you ?',\n",
       "    'll . my dad is a police officer and they have a sports team too',\n",
       "    'oh you should get your license',\n",
       "    'okay you have a good day nice talking with you !',\n",
       "    'i play some ball for a living .',\n",
       "    'me too ! my asthma is really embarrassing and makes me uncomfortable around others .',\n",
       "    'netflix and good food is the best . maybe lobster , my favorite seafood . where ya from ?',\n",
       "    'oh nice . why is that ?',\n",
       "    'sounds fun ! i helped my wife with health issues , too .',\n",
       "    \"i am a night owl . i think i'll play the piano a little before bed .\",\n",
       "    'just the real ones , not a big game person',\n",
       "    \"i could be the next mrs . adam levine . please , i'll buy you 10 mangoes .\",\n",
       "    \"do you like dogs i've usually to talk\",\n",
       "    'what did she teach ? my mom stayed home with my and my 3 older siblings',\n",
       "    'neither do i , i am just a photographer , and that is already a ot of energy',\n",
       "    'no , i say i am average at 5 4 . are you vertically challenged ?',\n",
       "    'what is your favorite meat to eat ?'],\n",
       "   'history': [\"hi , how are you doing ? i'm getting ready to do some cheetah chasing to stay in shape .\",\n",
       "    'you must be very fast . hunting is one of my favorite hobbies .',\n",
       "    'i am ! for my hobby i like to do canning or some whittling .',\n",
       "    'i also remodel homes when i am not out bow hunting .',\n",
       "    \"that's neat . when i was in high school i placed 6th in 100m dash !\",\n",
       "    \"that's awesome . do you have a favorite season or time of year ?\",\n",
       "    'i do not . but i do have a favorite meat since that is all i eat exclusively .']},\n",
       "  {'candidates': ['i am listening to system of a down , i wonder if your cat would like them',\n",
       "    'i absolutely agree , women are just as strong and capable .',\n",
       "    'in denmark with my grandma . what about you ?',\n",
       "    'i live in backcountry michigan . i encounter many sick , injured wildlife daily !',\n",
       "    'i am great and you',\n",
       "    'i am a big foodie , i love to bake . how about you ?',\n",
       "    'dance ! ! i win alot of mone and trifies . . what do u do four fun ?',\n",
       "    'do you do any sports ? swimming helps me keep my energy up .',\n",
       "    'they are excellent for the environment .',\n",
       "    'i am going to catch some fish and think this over . thanks dog !',\n",
       "    'i am doing well ! how about you ?',\n",
       "    'i like old cars better new cars are to expensive',\n",
       "    \"i've met bill once . he seems like a nice guy .\",\n",
       "    \"oh that is amazing . i've been trying to find someone who can help him\",\n",
       "    'i am in my early 30s , what you do for living',\n",
       "    'so , you are in college ? i took foreign language in college .',\n",
       "    'i just turned 30 the other day',\n",
       "    'what a coincidence i live up in anchorage',\n",
       "    'that would be interesting . i am going to be a forensic psychologist .',\n",
       "    'i like chicken or macaroni and cheese .'],\n",
       "   'history': [\"hi , how are you doing ? i'm getting ready to do some cheetah chasing to stay in shape .\",\n",
       "    'you must be very fast . hunting is one of my favorite hobbies .',\n",
       "    'i am ! for my hobby i like to do canning or some whittling .',\n",
       "    'i also remodel homes when i am not out bow hunting .',\n",
       "    \"that's neat . when i was in high school i placed 6th in 100m dash !\",\n",
       "    \"that's awesome . do you have a favorite season or time of year ?\",\n",
       "    'i do not . but i do have a favorite meat since that is all i eat exclusively .',\n",
       "    'what is your favorite meat to eat ?',\n",
       "    'i would have to say its prime rib . do you have any favorite foods ?']},\n",
       "  {'candidates': ['that sounds nice . do you make your own ?',\n",
       "    'i had a simple lunch so that i make my supper heavy after beach .',\n",
       "    'nice i may be able to beat you my hair is bright purple',\n",
       "    'not really i am kind of an introvert',\n",
       "    'well currently i am going to the university of chicago to obtain a law degree',\n",
       "    'also , my parents came with me , because they are on a break from teaching !',\n",
       "    'oh , i am sorry . want to come play tennis with my two sisters and me ?',\n",
       "    'wow ! 2 sons . john and wayne . you play guitar good ?',\n",
       "    'what do you do all day then ?',\n",
       "    'i work from home , what about you ?',\n",
       "    'that is no good . have glasses ?',\n",
       "    'just chilling . watching netflix . so what are you reading ?',\n",
       "    'i love food too . especially fine dining .',\n",
       "    'what do you like to watch ?',\n",
       "    'i do not have to work anymore , thank goodness',\n",
       "    'no , not really . i am in kansas .',\n",
       "    'i love movies . especially disney .',\n",
       "    'no i do not . what kinds of dogs do you have',\n",
       "    \"they won't , but i'll someday . what are you hobbies ?\",\n",
       "    'i am going to watch football . what are you canning ?'],\n",
       "   'history': [\"hi , how are you doing ? i'm getting ready to do some cheetah chasing to stay in shape .\",\n",
       "    'you must be very fast . hunting is one of my favorite hobbies .',\n",
       "    'i am ! for my hobby i like to do canning or some whittling .',\n",
       "    'i also remodel homes when i am not out bow hunting .',\n",
       "    \"that's neat . when i was in high school i placed 6th in 100m dash !\",\n",
       "    \"that's awesome . do you have a favorite season or time of year ?\",\n",
       "    'i do not . but i do have a favorite meat since that is all i eat exclusively .',\n",
       "    'what is your favorite meat to eat ?',\n",
       "    'i would have to say its prime rib . do you have any favorite foods ?',\n",
       "    'i like chicken or macaroni and cheese .',\n",
       "    'do you have anything planned for today ? i think i am going to do some canning .']},\n",
       "  {'candidates': ['awesome . so what do you do for a living ?',\n",
       "    'you are telling the truth lol',\n",
       "    'haha yea i love cookies . i sleep way to much to . you like music ?',\n",
       "    'that is nice to know . i travel due to being financially stable .',\n",
       "    'i am sure you can . california is full of opportunities .',\n",
       "    \"they're fun . i also wanted to be a rock star as i love the music .\",\n",
       "    'you need a hobby something you can do in small segments at night',\n",
       "    'hi , i love halloween , so what do you like to do for fun ?',\n",
       "    'is that a long movie ? few hours ? that is what i spend at the pool',\n",
       "    'tennis sounds interesting ! yes , i am ! how about you ?',\n",
       "    'very well , thank you . how are you today ?',\n",
       "    'i like a cashier at my bank . i stare at her at a distance to flirt .',\n",
       "    'yes . thank you for the chat .',\n",
       "    'that is super sweet , high school sweetheart kind of thing',\n",
       "    'hey . my favorite color is pink . how about you ?',\n",
       "    \"nice ! i don't go out much because i am busy at my accounting job .\",\n",
       "    \"oh my gosh i don't know what i'd do if i had to get a job !\",\n",
       "    'that would still be buying it online !',\n",
       "    'was okay . dog woke me up and just getting ready for a date .',\n",
       "    'if i have time outside of hunting and remodeling homes . which is not much !'],\n",
       "   'history': [\"hi , how are you doing ? i'm getting ready to do some cheetah chasing to stay in shape .\",\n",
       "    'you must be very fast . hunting is one of my favorite hobbies .',\n",
       "    'i am ! for my hobby i like to do canning or some whittling .',\n",
       "    'i also remodel homes when i am not out bow hunting .',\n",
       "    \"that's neat . when i was in high school i placed 6th in 100m dash !\",\n",
       "    \"that's awesome . do you have a favorite season or time of year ?\",\n",
       "    'i do not . but i do have a favorite meat since that is all i eat exclusively .',\n",
       "    'what is your favorite meat to eat ?',\n",
       "    'i would have to say its prime rib . do you have any favorite foods ?',\n",
       "    'i like chicken or macaroni and cheese .',\n",
       "    'do you have anything planned for today ? i think i am going to do some canning .',\n",
       "    'i am going to watch football . what are you canning ?',\n",
       "    'i think i will can some jam . do you also play footfall for fun ?']}]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'candidates': [[547,\n",
       "    1631,\n",
       "    509,\n",
       "    2433,\n",
       "    556,\n",
       "    281,\n",
       "    2590,\n",
       "    240,\n",
       "    620,\n",
       "    606,\n",
       "    868,\n",
       "    999,\n",
       "    481,\n",
       "    12810,\n",
       "    239],\n",
       "   [249,\n",
       "    1302,\n",
       "    485,\n",
       "    2985,\n",
       "    589,\n",
       "    1301,\n",
       "    1099,\n",
       "    850,\n",
       "    239,\n",
       "    507,\n",
       "    2191,\n",
       "    510,\n",
       "    1064,\n",
       "    2589,\n",
       "    239],\n",
       "   [862, 12618, 33292, 512, 551, 620, 249, 2275, 3754, 556, 1971],\n",
       "   [1439, 668, 823, 485, 2572, 609, 9, 6987, 39731, 1381, 1122],\n",
       "   [249, 976, 649, 22044, 17082, 239, 599, 670, 512, 257],\n",
       "   [664, 239, 249, 1894, 1957, 17367, 239],\n",
       "   [249,\n",
       "    2275,\n",
       "    249,\n",
       "    558,\n",
       "    246,\n",
       "    2332,\n",
       "    240,\n",
       "    249,\n",
       "    256,\n",
       "    258,\n",
       "    246,\n",
       "    1541,\n",
       "    1631,\n",
       "    239,\n",
       "    600,\n",
       "    256,\n",
       "    716,\n",
       "    1871,\n",
       "    2590,\n",
       "    998,\n",
       "    843,\n",
       "    3172],\n",
       "   [1439,\n",
       "    669,\n",
       "    249,\n",
       "    727,\n",
       "    5271,\n",
       "    249,\n",
       "    2200,\n",
       "    1374,\n",
       "    556,\n",
       "    481,\n",
       "    2272,\n",
       "    547,\n",
       "    3898,\n",
       "    4121,\n",
       "    239],\n",
       "   [3569,\n",
       "    718,\n",
       "    640,\n",
       "    512,\n",
       "    257,\n",
       "    249,\n",
       "    256,\n",
       "    258,\n",
       "    3658,\n",
       "    2340,\n",
       "    556,\n",
       "    547,\n",
       "    884,\n",
       "    3067,\n",
       "    488,\n",
       "    280,\n",
       "    2387,\n",
       "    239],\n",
       "   [641, 512, 2779, 485, 704, 1583, 1736, 6454, 257, 249, 509, 239],\n",
       "   [525, 544, 1424, 485, 1344, 267, 640, 512, 246, 21394, 11487, 257],\n",
       "   [3569,\n",
       "    240,\n",
       "    249,\n",
       "    256,\n",
       "    258,\n",
       "    1273,\n",
       "    773,\n",
       "    239,\n",
       "    249,\n",
       "    256,\n",
       "    258,\n",
       "    246,\n",
       "    18806,\n",
       "    239,\n",
       "    718,\n",
       "    670,\n",
       "    512,\n",
       "    257],\n",
       "   [249, 256, 258, 284, 1218, 1122],\n",
       "   [3569, 655, 239, 718, 640, 512, 1873, 257],\n",
       "   [249, 3548, 1623, 718, 20891, 525, 759, 580, 239],\n",
       "   [1439, 2207, 512, 587, 595, 699, 599, 512, 640, 1629, 1811],\n",
       "   [1173,\n",
       "    4682,\n",
       "    510,\n",
       "    485,\n",
       "    5539,\n",
       "    267,\n",
       "    606,\n",
       "    640,\n",
       "    1081,\n",
       "    562,\n",
       "    531,\n",
       "    659,\n",
       "    2791,\n",
       "    2175,\n",
       "    239],\n",
       "   [249,\n",
       "    3545,\n",
       "    6652,\n",
       "    4121,\n",
       "    239,\n",
       "    599,\n",
       "    544,\n",
       "    704,\n",
       "    3898,\n",
       "    7033,\n",
       "    257,\n",
       "    1519,\n",
       "    544,\n",
       "    3111,\n",
       "    239],\n",
       "   [26247, 6669, 2722, 246, 1322, 498, 1129, 239],\n",
       "   [512,\n",
       "    1259,\n",
       "    580,\n",
       "    963,\n",
       "    1708,\n",
       "    239,\n",
       "    5408,\n",
       "    544,\n",
       "    566,\n",
       "    498,\n",
       "    547,\n",
       "    3898,\n",
       "    31054,\n",
       "    239]],\n",
       "  'history': [[3569,\n",
       "    240,\n",
       "    718,\n",
       "    640,\n",
       "    512,\n",
       "    1273,\n",
       "    257,\n",
       "    249,\n",
       "    256,\n",
       "    258,\n",
       "    1381,\n",
       "    1011,\n",
       "    485,\n",
       "    587,\n",
       "    803,\n",
       "    1626,\n",
       "    17017,\n",
       "    7150,\n",
       "    485,\n",
       "    1558,\n",
       "    500,\n",
       "    3852,\n",
       "    239]]},\n",
       " {'candidates': [[3570, 249, 1048, 1273, 862, 718, 640, 512, 257],\n",
       "   [665, 846, 649, 525, 239, 587, 512, 2200, 5145, 257],\n",
       "   [1056, 1033, 1168, 512, 3041, 257, 249, 2785, 1493, 8336, 562, 1519, 239],\n",
       "   [249, 22830, 8787, 491, 246, 3935, 16198, 267, 488, 512, 257],\n",
       "   [587, 512, 2425, 4183, 498, 5089],\n",
       "   [249, 1048, 620, 3574, 525, 249, 649, 485, 7610, 989, 488, 8407],\n",
       "   [718, 640, 704, 14424, 6074, 257],\n",
       "   [1439,\n",
       "    239,\n",
       "    249,\n",
       "    1048,\n",
       "    2286,\n",
       "    485,\n",
       "    481,\n",
       "    6860,\n",
       "    500,\n",
       "    246,\n",
       "    1378,\n",
       "    485,\n",
       "    2873,\n",
       "    4316,\n",
       "    239],\n",
       "   [1439, 512, 604, 4065, 498, 720],\n",
       "   [2817,\n",
       "    544,\n",
       "    547,\n",
       "    3898,\n",
       "    240,\n",
       "    568,\n",
       "    249,\n",
       "    759,\n",
       "    3859,\n",
       "    525,\n",
       "    989,\n",
       "    2534,\n",
       "    485,\n",
       "    3138,\n",
       "    239,\n",
       "    25636],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    895,\n",
       "    512,\n",
       "    3183,\n",
       "    485,\n",
       "    580,\n",
       "    6934,\n",
       "    239,\n",
       "    851,\n",
       "    510,\n",
       "    1959,\n",
       "    512,\n",
       "    1800,\n",
       "    566,\n",
       "    239],\n",
       "   [867, 4954, 600, 640, 481, 1432, 240, 718, 670, 512, 257],\n",
       "   [512, 587, 2212, 257, 599, 1376, 498, 2212, 587, 512, 587, 257],\n",
       "   [249, 1119, 1811, 7896, 17945, 504, 9198, 1460, 239],\n",
       "   [1141,\n",
       "    249,\n",
       "    788,\n",
       "    239,\n",
       "    587,\n",
       "    512,\n",
       "    871,\n",
       "    825,\n",
       "    670,\n",
       "    1826,\n",
       "    257,\n",
       "    249,\n",
       "    587,\n",
       "    240,\n",
       "    507,\n",
       "    544,\n",
       "    599,\n",
       "    249,\n",
       "    823,\n",
       "    239],\n",
       "   [881,\n",
       "    239,\n",
       "    249,\n",
       "    2275,\n",
       "    507,\n",
       "    641,\n",
       "    4423,\n",
       "    239,\n",
       "    481,\n",
       "    2104,\n",
       "    976,\n",
       "    7137,\n",
       "    547,\n",
       "    1674,\n",
       "    741,\n",
       "    239],\n",
       "   [640, 606, 6563, 485, 2200, 10725],\n",
       "   [249, 1048, 3717, 488, 604, 589, 498, 547, 3626, 15513, 1245],\n",
       "   [600,\n",
       "    6615,\n",
       "    510,\n",
       "    620,\n",
       "    240,\n",
       "    249,\n",
       "    1419,\n",
       "    1841,\n",
       "    670,\n",
       "    5895,\n",
       "    4,\n",
       "    15127,\n",
       "    246,\n",
       "    850,\n",
       "    912,\n",
       "    498,\n",
       "    688,\n",
       "    239],\n",
       "   [249, 1359, 5371, 4621, 7654, 669, 249, 1048, 595, 551, 2877, 5408, 239]],\n",
       "  'history': [[3569,\n",
       "    240,\n",
       "    718,\n",
       "    640,\n",
       "    512,\n",
       "    1273,\n",
       "    257,\n",
       "    249,\n",
       "    256,\n",
       "    258,\n",
       "    1381,\n",
       "    1011,\n",
       "    485,\n",
       "    587,\n",
       "    803,\n",
       "    1626,\n",
       "    17017,\n",
       "    7150,\n",
       "    485,\n",
       "    1558,\n",
       "    500,\n",
       "    3852,\n",
       "    239],\n",
       "   [512,\n",
       "    1259,\n",
       "    580,\n",
       "    963,\n",
       "    1708,\n",
       "    239,\n",
       "    5408,\n",
       "    544,\n",
       "    566,\n",
       "    498,\n",
       "    547,\n",
       "    3898,\n",
       "    31054,\n",
       "    239],\n",
       "   [249,\n",
       "    1048,\n",
       "    267,\n",
       "    562,\n",
       "    547,\n",
       "    18722,\n",
       "    249,\n",
       "    649,\n",
       "    485,\n",
       "    587,\n",
       "    2274,\n",
       "    826,\n",
       "    522,\n",
       "    803,\n",
       "    684,\n",
       "    22962,\n",
       "    239]]},\n",
       " {'candidates': [[685, 600, 587, 568, 249, 937, 664, 485, 688, 518, 264],\n",
       "   [249, 604, 2389, 1381, 1412, 556, 1463, 239],\n",
       "   [249,\n",
       "    1894,\n",
       "    500,\n",
       "    8041,\n",
       "    240,\n",
       "    599,\n",
       "    1376,\n",
       "    498,\n",
       "    2404,\n",
       "    587,\n",
       "    512,\n",
       "    587,\n",
       "    500,\n",
       "    21844,\n",
       "    257],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    620,\n",
       "    8241,\n",
       "    267,\n",
       "    29852,\n",
       "    37590,\n",
       "    488,\n",
       "    1584,\n",
       "    4542,\n",
       "    2697,\n",
       "    2310,\n",
       "    256,\n",
       "    241,\n",
       "    7087,\n",
       "    267],\n",
       "   [664,\n",
       "    240,\n",
       "    507,\n",
       "    1532,\n",
       "    247,\n",
       "    256,\n",
       "    241,\n",
       "    525,\n",
       "    1393,\n",
       "    239,\n",
       "    587,\n",
       "    512,\n",
       "    4410,\n",
       "    246,\n",
       "    1322],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    912,\n",
       "    600,\n",
       "    640,\n",
       "    1582,\n",
       "    270,\n",
       "    599,\n",
       "    587,\n",
       "    512,\n",
       "    587,\n",
       "    562,\n",
       "    1129,\n",
       "    257],\n",
       "   [249,\n",
       "    1048,\n",
       "    8447,\n",
       "    589,\n",
       "    850,\n",
       "    518,\n",
       "    264,\n",
       "    239,\n",
       "    547,\n",
       "    1631,\n",
       "    2443,\n",
       "    510,\n",
       "    485,\n",
       "    727,\n",
       "    246,\n",
       "    1890,\n",
       "    488,\n",
       "    1462,\n",
       "    551],\n",
       "   [249,\n",
       "    509,\n",
       "    3105,\n",
       "    504,\n",
       "    38342,\n",
       "    850,\n",
       "    240,\n",
       "    620,\n",
       "    6047,\n",
       "    246,\n",
       "    2455,\n",
       "    500,\n",
       "    547,\n",
       "    1362],\n",
       "   [1304,\n",
       "    240,\n",
       "    249,\n",
       "    994,\n",
       "    595,\n",
       "    972,\n",
       "    512,\n",
       "    240,\n",
       "    987,\n",
       "    1006,\n",
       "    481,\n",
       "    4556,\n",
       "    568,\n",
       "    547,\n",
       "    1362,\n",
       "    544,\n",
       "    3209,\n",
       "    240,\n",
       "    1370,\n",
       "    510,\n",
       "    245],\n",
       "   [3570, 718, 640, 254, 1937],\n",
       "   [2548,\n",
       "    239,\n",
       "    239,\n",
       "    239,\n",
       "    547,\n",
       "    1999,\n",
       "    1119,\n",
       "    3138,\n",
       "    2848,\n",
       "    525,\n",
       "    256,\n",
       "    252,\n",
       "    895,\n",
       "    249,\n",
       "    2785,\n",
       "    507],\n",
       "   [249, 1048, 531, 19102, 239, 599, 587, 512, 587, 257],\n",
       "   [599, 587, 704, 1999, 587, 257, 547, 1650, 544, 246, 17949, 239],\n",
       "   [718, 640, 512, 9679, 507, 257],\n",
       "   [249, 976, 1048, 834, 239, 1424, 1592, 485, 512, 834, 239],\n",
       "   [2548, 239, 7639, 639, 507, 649, 1996, 655, 257],\n",
       "   [566, 2332, 239, 520, 256, 252, 9458, 1003],\n",
       "   [664,\n",
       "    488,\n",
       "    589,\n",
       "    1175,\n",
       "    544,\n",
       "    7192,\n",
       "    815,\n",
       "    510,\n",
       "    895,\n",
       "    759,\n",
       "    256,\n",
       "    241,\n",
       "    249,\n",
       "    1085,\n",
       "    246,\n",
       "    762,\n",
       "    485,\n",
       "    2929,\n",
       "    556],\n",
       "   [249,\n",
       "    1894,\n",
       "    500,\n",
       "    27103,\n",
       "    240,\n",
       "    488,\n",
       "    547,\n",
       "    1463,\n",
       "    1894,\n",
       "    500,\n",
       "    6826,\n",
       "    240,\n",
       "    620,\n",
       "    249,\n",
       "    1623],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    6702,\n",
       "    239,\n",
       "    587,\n",
       "    512,\n",
       "    604,\n",
       "    246,\n",
       "    3898,\n",
       "    7033,\n",
       "    522,\n",
       "    720,\n",
       "    498,\n",
       "    1803,\n",
       "    257]],\n",
       "  'history': [[3569,\n",
       "    240,\n",
       "    718,\n",
       "    640,\n",
       "    512,\n",
       "    1273,\n",
       "    257,\n",
       "    249,\n",
       "    256,\n",
       "    258,\n",
       "    1381,\n",
       "    1011,\n",
       "    485,\n",
       "    587,\n",
       "    803,\n",
       "    1626,\n",
       "    17017,\n",
       "    7150,\n",
       "    485,\n",
       "    1558,\n",
       "    500,\n",
       "    3852,\n",
       "    239],\n",
       "   [512,\n",
       "    1259,\n",
       "    580,\n",
       "    963,\n",
       "    1708,\n",
       "    239,\n",
       "    5408,\n",
       "    544,\n",
       "    566,\n",
       "    498,\n",
       "    547,\n",
       "    3898,\n",
       "    31054,\n",
       "    239],\n",
       "   [249,\n",
       "    1048,\n",
       "    267,\n",
       "    562,\n",
       "    547,\n",
       "    18722,\n",
       "    249,\n",
       "    649,\n",
       "    485,\n",
       "    587,\n",
       "    2274,\n",
       "    826,\n",
       "    522,\n",
       "    803,\n",
       "    684,\n",
       "    22962,\n",
       "    239],\n",
       "   [249, 1359, 5371, 4621, 7654, 669, 249, 1048, 595, 551, 2877, 5408, 239],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    8088,\n",
       "    239,\n",
       "    669,\n",
       "    249,\n",
       "    509,\n",
       "    500,\n",
       "    1583,\n",
       "    1736,\n",
       "    249,\n",
       "    2160,\n",
       "    35716,\n",
       "    500,\n",
       "    8582,\n",
       "    48,\n",
       "    258,\n",
       "    9241,\n",
       "    267]]},\n",
       " {'candidates': [[595,\n",
       "    976,\n",
       "    240,\n",
       "    507,\n",
       "    544,\n",
       "    668,\n",
       "    246,\n",
       "    1220,\n",
       "    3935,\n",
       "    4593,\n",
       "    3173,\n",
       "    239,\n",
       "    599,\n",
       "    670,\n",
       "    512,\n",
       "    240,\n",
       "    599,\n",
       "    587,\n",
       "    512,\n",
       "    587,\n",
       "    257],\n",
       "   [510, 834, 267, 989, 1120, 937, 249, 1048, 620, 10178],\n",
       "   [747, 32569, 2082, 544, 806, 622, 13355, 812, 580],\n",
       "   [685,\n",
       "    267,\n",
       "    249,\n",
       "    699,\n",
       "    718,\n",
       "    485,\n",
       "    580,\n",
       "    702,\n",
       "    1291,\n",
       "    239,\n",
       "    512,\n",
       "    257,\n",
       "    249,\n",
       "    587,\n",
       "    595,\n",
       "    966,\n",
       "    783,\n",
       "    1662,\n",
       "    239,\n",
       "    512,\n",
       "    257],\n",
       "   [665,\n",
       "    239,\n",
       "    547,\n",
       "    1650,\n",
       "    544,\n",
       "    246,\n",
       "    2448,\n",
       "    3802,\n",
       "    488,\n",
       "    600,\n",
       "    604,\n",
       "    246,\n",
       "    7396,\n",
       "    2855,\n",
       "    834],\n",
       "   [1141, 512, 994, 727, 704, 8200],\n",
       "   [1304, 512, 604, 246, 870, 850, 1875, 1592, 556, 512, 267],\n",
       "   [249, 2200, 803, 2215, 562, 246, 1885, 239],\n",
       "   [510,\n",
       "    834,\n",
       "    267,\n",
       "    547,\n",
       "    34430,\n",
       "    544,\n",
       "    976,\n",
       "    9084,\n",
       "    488,\n",
       "    2191,\n",
       "    510,\n",
       "    4447,\n",
       "    785,\n",
       "    1709,\n",
       "    239],\n",
       "   [7998,\n",
       "    1620,\n",
       "    272,\n",
       "    488,\n",
       "    870,\n",
       "    2044,\n",
       "    544,\n",
       "    481,\n",
       "    1432,\n",
       "    239,\n",
       "    1096,\n",
       "    21888,\n",
       "    240,\n",
       "    547,\n",
       "    3898,\n",
       "    26286,\n",
       "    239,\n",
       "    806,\n",
       "    2788,\n",
       "    617,\n",
       "    257],\n",
       "   [1141, 1875, 239, 895, 544, 525, 257],\n",
       "   [2358, 2664, 267, 249, 2840, 547, 2093, 556, 6558, 6769, 240, 834, 239],\n",
       "   [249,\n",
       "    1048,\n",
       "    246,\n",
       "    995,\n",
       "    14002,\n",
       "    239,\n",
       "    249,\n",
       "    825,\n",
       "    249,\n",
       "    256,\n",
       "    665,\n",
       "    2200,\n",
       "    481,\n",
       "    9768,\n",
       "    246,\n",
       "    909,\n",
       "    781,\n",
       "    943,\n",
       "    239],\n",
       "   [668, 481, 1582, 1608, 240, 595, 246, 1393, 2467, 1800],\n",
       "   [249,\n",
       "    635,\n",
       "    580,\n",
       "    481,\n",
       "    1115,\n",
       "    8417,\n",
       "    239,\n",
       "    3196,\n",
       "    27329,\n",
       "    239,\n",
       "    1572,\n",
       "    240,\n",
       "    249,\n",
       "    256,\n",
       "    665,\n",
       "    3487,\n",
       "    512,\n",
       "    5895,\n",
       "    923,\n",
       "    2993,\n",
       "    239],\n",
       "   [587, 512, 649, 4954, 249, 256, 527, 2697, 485, 1375],\n",
       "   [599,\n",
       "    626,\n",
       "    520,\n",
       "    5423,\n",
       "    257,\n",
       "    547,\n",
       "    1631,\n",
       "    2852,\n",
       "    1163,\n",
       "    556,\n",
       "    547,\n",
       "    488,\n",
       "    547,\n",
       "    281,\n",
       "    2892,\n",
       "    11307],\n",
       "   [2870,\n",
       "    587,\n",
       "    249,\n",
       "    240,\n",
       "    249,\n",
       "    1048,\n",
       "    668,\n",
       "    246,\n",
       "    14414,\n",
       "    240,\n",
       "    488,\n",
       "    525,\n",
       "    544,\n",
       "    1245,\n",
       "    246,\n",
       "    1479,\n",
       "    498,\n",
       "    2940],\n",
       "   [664,\n",
       "    240,\n",
       "    249,\n",
       "    937,\n",
       "    249,\n",
       "    1048,\n",
       "    8453,\n",
       "    491,\n",
       "    284,\n",
       "    282,\n",
       "    239,\n",
       "    640,\n",
       "    512,\n",
       "    29960,\n",
       "    10293,\n",
       "    257],\n",
       "   [599, 544, 704, 3898, 5089, 485, 2425, 257]],\n",
       "  'history': [[3569,\n",
       "    240,\n",
       "    718,\n",
       "    640,\n",
       "    512,\n",
       "    1273,\n",
       "    257,\n",
       "    249,\n",
       "    256,\n",
       "    258,\n",
       "    1381,\n",
       "    1011,\n",
       "    485,\n",
       "    587,\n",
       "    803,\n",
       "    1626,\n",
       "    17017,\n",
       "    7150,\n",
       "    485,\n",
       "    1558,\n",
       "    500,\n",
       "    3852,\n",
       "    239],\n",
       "   [512,\n",
       "    1259,\n",
       "    580,\n",
       "    963,\n",
       "    1708,\n",
       "    239,\n",
       "    5408,\n",
       "    544,\n",
       "    566,\n",
       "    498,\n",
       "    547,\n",
       "    3898,\n",
       "    31054,\n",
       "    239],\n",
       "   [249,\n",
       "    1048,\n",
       "    267,\n",
       "    562,\n",
       "    547,\n",
       "    18722,\n",
       "    249,\n",
       "    649,\n",
       "    485,\n",
       "    587,\n",
       "    2274,\n",
       "    826,\n",
       "    522,\n",
       "    803,\n",
       "    684,\n",
       "    22962,\n",
       "    239],\n",
       "   [249, 1359, 5371, 4621, 7654, 669, 249, 1048, 595, 551, 2877, 5408, 239],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    8088,\n",
       "    239,\n",
       "    669,\n",
       "    249,\n",
       "    509,\n",
       "    500,\n",
       "    1583,\n",
       "    1736,\n",
       "    249,\n",
       "    2160,\n",
       "    35716,\n",
       "    500,\n",
       "    8582,\n",
       "    48,\n",
       "    258,\n",
       "    9241,\n",
       "    267],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    6702,\n",
       "    239,\n",
       "    587,\n",
       "    512,\n",
       "    604,\n",
       "    246,\n",
       "    3898,\n",
       "    7033,\n",
       "    522,\n",
       "    720,\n",
       "    498,\n",
       "    1803,\n",
       "    257],\n",
       "   [249,\n",
       "    587,\n",
       "    595,\n",
       "    239,\n",
       "    568,\n",
       "    249,\n",
       "    587,\n",
       "    604,\n",
       "    246,\n",
       "    3898,\n",
       "    5089,\n",
       "    1234,\n",
       "    525,\n",
       "    544,\n",
       "    589,\n",
       "    249,\n",
       "    2425,\n",
       "    22426,\n",
       "    239]]},\n",
       " {'candidates': [[249,\n",
       "    1048,\n",
       "    3053,\n",
       "    485,\n",
       "    3424,\n",
       "    498,\n",
       "    246,\n",
       "    714,\n",
       "    240,\n",
       "    249,\n",
       "    2496,\n",
       "    645,\n",
       "    704,\n",
       "    3387,\n",
       "    636,\n",
       "    649,\n",
       "    688],\n",
       "   [249, 3642, 3798, 240, 1909, 640, 668, 557, 2074, 488, 4489, 239],\n",
       "   [500, 1666, 2546, 556, 547, 6778, 239, 599, 670, 512, 257],\n",
       "   [249,\n",
       "    1894,\n",
       "    500,\n",
       "    1923,\n",
       "    3138,\n",
       "    19406,\n",
       "    239,\n",
       "    249,\n",
       "    8043,\n",
       "    1272,\n",
       "    2862,\n",
       "    240,\n",
       "    6291,\n",
       "    22810,\n",
       "    6858,\n",
       "    267],\n",
       "   [249, 1048, 1424, 488, 512],\n",
       "   [249,\n",
       "    1048,\n",
       "    246,\n",
       "    1393,\n",
       "    2195,\n",
       "    1696,\n",
       "    240,\n",
       "    249,\n",
       "    1119,\n",
       "    485,\n",
       "    19007,\n",
       "    239,\n",
       "    718,\n",
       "    670,\n",
       "    512,\n",
       "    257],\n",
       "   [2929,\n",
       "    267,\n",
       "    267,\n",
       "    249,\n",
       "    3285,\n",
       "    501,\n",
       "    1479,\n",
       "    498,\n",
       "    36920,\n",
       "    488,\n",
       "    887,\n",
       "    14343,\n",
       "    239,\n",
       "    239,\n",
       "    599,\n",
       "    587,\n",
       "    254,\n",
       "    587,\n",
       "    1667,\n",
       "    2664,\n",
       "    257],\n",
       "   [587, 512, 587, 775, 7396, 257, 7117, 8346, 510, 1178, 547, 2940, 609, 239],\n",
       "   [600, 640, 6027, 562, 481, 9961, 239],\n",
       "   [249,\n",
       "    1048,\n",
       "    797,\n",
       "    485,\n",
       "    2560,\n",
       "    803,\n",
       "    3316,\n",
       "    488,\n",
       "    825,\n",
       "    616,\n",
       "    715,\n",
       "    239,\n",
       "    2190,\n",
       "    2585,\n",
       "    267],\n",
       "   [249, 1048, 1273, 862, 267, 718, 670, 512, 257],\n",
       "   [249, 649, 1122, 3977, 1198, 783, 3977, 640, 485, 5528],\n",
       "   [249,\n",
       "    256,\n",
       "    527,\n",
       "    1665,\n",
       "    3670,\n",
       "    1098,\n",
       "    239,\n",
       "    487,\n",
       "    2491,\n",
       "    649,\n",
       "    246,\n",
       "    1875,\n",
       "    1567,\n",
       "    239],\n",
       "   [1141,\n",
       "    525,\n",
       "    544,\n",
       "    3691,\n",
       "    239,\n",
       "    249,\n",
       "    256,\n",
       "    527,\n",
       "    694,\n",
       "    1204,\n",
       "    485,\n",
       "    1085,\n",
       "    1184,\n",
       "    763,\n",
       "    759,\n",
       "    1150,\n",
       "    575],\n",
       "   [249, 1048, 500, 547, 2418, 37036, 240, 599, 512, 587, 562, 1885],\n",
       "   [620, 240, 512, 640, 500, 3797, 257, 249, 948, 7065, 4636, 500, 3797, 239],\n",
       "   [249, 668, 899, 6828, 481, 728, 850],\n",
       "   [599, 246, 9183, 249, 1894, 609, 500, 31350, 1028],\n",
       "   [525,\n",
       "    636,\n",
       "    580,\n",
       "    3666,\n",
       "    239,\n",
       "    249,\n",
       "    1048,\n",
       "    797,\n",
       "    485,\n",
       "    580,\n",
       "    246,\n",
       "    24486,\n",
       "    19454,\n",
       "    239],\n",
       "   [249, 649, 5867, 522, 32184, 488, 6821, 239]],\n",
       "  'history': [[3569,\n",
       "    240,\n",
       "    718,\n",
       "    640,\n",
       "    512,\n",
       "    1273,\n",
       "    257,\n",
       "    249,\n",
       "    256,\n",
       "    258,\n",
       "    1381,\n",
       "    1011,\n",
       "    485,\n",
       "    587,\n",
       "    803,\n",
       "    1626,\n",
       "    17017,\n",
       "    7150,\n",
       "    485,\n",
       "    1558,\n",
       "    500,\n",
       "    3852,\n",
       "    239],\n",
       "   [512,\n",
       "    1259,\n",
       "    580,\n",
       "    963,\n",
       "    1708,\n",
       "    239,\n",
       "    5408,\n",
       "    544,\n",
       "    566,\n",
       "    498,\n",
       "    547,\n",
       "    3898,\n",
       "    31054,\n",
       "    239],\n",
       "   [249,\n",
       "    1048,\n",
       "    267,\n",
       "    562,\n",
       "    547,\n",
       "    18722,\n",
       "    249,\n",
       "    649,\n",
       "    485,\n",
       "    587,\n",
       "    2274,\n",
       "    826,\n",
       "    522,\n",
       "    803,\n",
       "    684,\n",
       "    22962,\n",
       "    239],\n",
       "   [249, 1359, 5371, 4621, 7654, 669, 249, 1048, 595, 551, 2877, 5408, 239],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    8088,\n",
       "    239,\n",
       "    669,\n",
       "    249,\n",
       "    509,\n",
       "    500,\n",
       "    1583,\n",
       "    1736,\n",
       "    249,\n",
       "    2160,\n",
       "    35716,\n",
       "    500,\n",
       "    8582,\n",
       "    48,\n",
       "    258,\n",
       "    9241,\n",
       "    267],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    6702,\n",
       "    239,\n",
       "    587,\n",
       "    512,\n",
       "    604,\n",
       "    246,\n",
       "    3898,\n",
       "    7033,\n",
       "    522,\n",
       "    720,\n",
       "    498,\n",
       "    1803,\n",
       "    257],\n",
       "   [249,\n",
       "    587,\n",
       "    595,\n",
       "    239,\n",
       "    568,\n",
       "    249,\n",
       "    587,\n",
       "    604,\n",
       "    246,\n",
       "    3898,\n",
       "    5089,\n",
       "    1234,\n",
       "    525,\n",
       "    544,\n",
       "    589,\n",
       "    249,\n",
       "    2425,\n",
       "    22426,\n",
       "    239],\n",
       "   [599, 544, 704, 3898, 5089, 485, 2425, 257],\n",
       "   [249,\n",
       "    636,\n",
       "    604,\n",
       "    485,\n",
       "    937,\n",
       "    987,\n",
       "    8511,\n",
       "    13099,\n",
       "    239,\n",
       "    587,\n",
       "    512,\n",
       "    604,\n",
       "    775,\n",
       "    3898,\n",
       "    17794,\n",
       "    257]]},\n",
       " {'candidates': [[525, 2358, 1875, 239, 587, 512, 925, 704, 1074, 257],\n",
       "   [249,\n",
       "    558,\n",
       "    246,\n",
       "    2834,\n",
       "    3311,\n",
       "    620,\n",
       "    525,\n",
       "    249,\n",
       "    925,\n",
       "    547,\n",
       "    8672,\n",
       "    2262,\n",
       "    861,\n",
       "    3620,\n",
       "    239],\n",
       "   [1875, 249, 1598, 580, 817, 485, 2523, 512, 547, 1133, 544, 2512, 5003],\n",
       "   [595, 976, 249, 1048, 1376, 498, 531, 3850, 28346],\n",
       "   [862,\n",
       "    7254,\n",
       "    249,\n",
       "    1048,\n",
       "    797,\n",
       "    485,\n",
       "    481,\n",
       "    5948,\n",
       "    498,\n",
       "    7490,\n",
       "    485,\n",
       "    16766,\n",
       "    246,\n",
       "    3321,\n",
       "    6937],\n",
       "   [1359,\n",
       "    240,\n",
       "    547,\n",
       "    1999,\n",
       "    939,\n",
       "    556,\n",
       "    510,\n",
       "    240,\n",
       "    912,\n",
       "    600,\n",
       "    640,\n",
       "    504,\n",
       "    246,\n",
       "    2158,\n",
       "    617,\n",
       "    8433,\n",
       "    267],\n",
       "   [1141,\n",
       "    240,\n",
       "    249,\n",
       "    1048,\n",
       "    1458,\n",
       "    239,\n",
       "    823,\n",
       "    485,\n",
       "    848,\n",
       "    2200,\n",
       "    10725,\n",
       "    556,\n",
       "    547,\n",
       "    867,\n",
       "    5176,\n",
       "    488,\n",
       "    510,\n",
       "    257],\n",
       "   [4605,\n",
       "    267,\n",
       "    280,\n",
       "    5383,\n",
       "    239,\n",
       "    2476,\n",
       "    488,\n",
       "    8550,\n",
       "    239,\n",
       "    512,\n",
       "    2200,\n",
       "    7907,\n",
       "    870,\n",
       "    257],\n",
       "   [599, 587, 512, 587, 589, 850, 674, 257],\n",
       "   [249, 1129, 617, 1163, 240, 599, 670, 512, 257],\n",
       "   [525, 544, 664, 870, 239, 604, 3435, 257],\n",
       "   [668,\n",
       "    15009,\n",
       "    239,\n",
       "    1811,\n",
       "    7998,\n",
       "    1620,\n",
       "    272,\n",
       "    239,\n",
       "    620,\n",
       "    599,\n",
       "    640,\n",
       "    512,\n",
       "    2644,\n",
       "    257],\n",
       "   [249, 1119, 2044, 834, 239, 2431, 1614, 5166, 239],\n",
       "   [599, 587, 512, 649, 485, 1832, 257],\n",
       "   [249, 587, 595, 604, 485, 1129, 2357, 240, 1784, 7516],\n",
       "   [664, 240, 595, 976, 239, 249, 1048, 500, 14102, 239],\n",
       "   [249, 1119, 6445, 239, 2431, 22703, 239],\n",
       "   [664, 249, 587, 595, 239, 599, 6673, 498, 4954, 587, 512, 604],\n",
       "   [600,\n",
       "    5011,\n",
       "    256,\n",
       "    241,\n",
       "    240,\n",
       "    568,\n",
       "    249,\n",
       "    256,\n",
       "    665,\n",
       "    7323,\n",
       "    239,\n",
       "    599,\n",
       "    640,\n",
       "    512,\n",
       "    31054,\n",
       "    257],\n",
       "   [249, 1048, 797, 485, 1832, 6210, 239, 599, 640, 512, 2274, 826, 257]],\n",
       "  'history': [[3569,\n",
       "    240,\n",
       "    718,\n",
       "    640,\n",
       "    512,\n",
       "    1273,\n",
       "    257,\n",
       "    249,\n",
       "    256,\n",
       "    258,\n",
       "    1381,\n",
       "    1011,\n",
       "    485,\n",
       "    587,\n",
       "    803,\n",
       "    1626,\n",
       "    17017,\n",
       "    7150,\n",
       "    485,\n",
       "    1558,\n",
       "    500,\n",
       "    3852,\n",
       "    239],\n",
       "   [512,\n",
       "    1259,\n",
       "    580,\n",
       "    963,\n",
       "    1708,\n",
       "    239,\n",
       "    5408,\n",
       "    544,\n",
       "    566,\n",
       "    498,\n",
       "    547,\n",
       "    3898,\n",
       "    31054,\n",
       "    239],\n",
       "   [249,\n",
       "    1048,\n",
       "    267,\n",
       "    562,\n",
       "    547,\n",
       "    18722,\n",
       "    249,\n",
       "    649,\n",
       "    485,\n",
       "    587,\n",
       "    2274,\n",
       "    826,\n",
       "    522,\n",
       "    803,\n",
       "    684,\n",
       "    22962,\n",
       "    239],\n",
       "   [249, 1359, 5371, 4621, 7654, 669, 249, 1048, 595, 551, 2877, 5408, 239],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    8088,\n",
       "    239,\n",
       "    669,\n",
       "    249,\n",
       "    509,\n",
       "    500,\n",
       "    1583,\n",
       "    1736,\n",
       "    249,\n",
       "    2160,\n",
       "    35716,\n",
       "    500,\n",
       "    8582,\n",
       "    48,\n",
       "    258,\n",
       "    9241,\n",
       "    267],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    6702,\n",
       "    239,\n",
       "    587,\n",
       "    512,\n",
       "    604,\n",
       "    246,\n",
       "    3898,\n",
       "    7033,\n",
       "    522,\n",
       "    720,\n",
       "    498,\n",
       "    1803,\n",
       "    257],\n",
       "   [249,\n",
       "    587,\n",
       "    595,\n",
       "    239,\n",
       "    568,\n",
       "    249,\n",
       "    587,\n",
       "    604,\n",
       "    246,\n",
       "    3898,\n",
       "    5089,\n",
       "    1234,\n",
       "    525,\n",
       "    544,\n",
       "    589,\n",
       "    249,\n",
       "    2425,\n",
       "    22426,\n",
       "    239],\n",
       "   [599, 544, 704, 3898, 5089, 485, 2425, 257],\n",
       "   [249,\n",
       "    636,\n",
       "    604,\n",
       "    485,\n",
       "    937,\n",
       "    987,\n",
       "    8511,\n",
       "    13099,\n",
       "    239,\n",
       "    587,\n",
       "    512,\n",
       "    604,\n",
       "    775,\n",
       "    3898,\n",
       "    17794,\n",
       "    257],\n",
       "   [249, 649, 5867, 522, 32184, 488, 6821, 239],\n",
       "   [587,\n",
       "    512,\n",
       "    604,\n",
       "    1033,\n",
       "    3825,\n",
       "    562,\n",
       "    1873,\n",
       "    257,\n",
       "    249,\n",
       "    825,\n",
       "    249,\n",
       "    1048,\n",
       "    797,\n",
       "    485,\n",
       "    587,\n",
       "    803,\n",
       "    2274,\n",
       "    826,\n",
       "    239]]},\n",
       " {'candidates': [[6702, 239, 620, 599, 587, 512, 587, 562, 246, 1885, 257],\n",
       "   [512, 640, 2202, 481, 2068, 518, 264],\n",
       "   [25636,\n",
       "    20588,\n",
       "    249,\n",
       "    1119,\n",
       "    9021,\n",
       "    239,\n",
       "    249,\n",
       "    1841,\n",
       "    638,\n",
       "    485,\n",
       "    889,\n",
       "    485,\n",
       "    239,\n",
       "    512,\n",
       "    649,\n",
       "    2848,\n",
       "    257],\n",
       "   [525,\n",
       "    544,\n",
       "    1875,\n",
       "    485,\n",
       "    699,\n",
       "    239,\n",
       "    249,\n",
       "    4410,\n",
       "    4173,\n",
       "    485,\n",
       "    1036,\n",
       "    21537,\n",
       "    6999,\n",
       "    239],\n",
       "   [249, 1048, 881, 512, 759, 239, 6983, 544, 1585, 498, 14922, 239],\n",
       "   [600,\n",
       "    256,\n",
       "    716,\n",
       "    2664,\n",
       "    239,\n",
       "    249,\n",
       "    1359,\n",
       "    961,\n",
       "    485,\n",
       "    580,\n",
       "    246,\n",
       "    2594,\n",
       "    3876,\n",
       "    557,\n",
       "    249,\n",
       "    1119,\n",
       "    481,\n",
       "    2848,\n",
       "    239],\n",
       "   [512, 966, 246, 18722, 846, 512, 759, 587, 500, 1220, 37634, 491, 995],\n",
       "   [3569,\n",
       "    240,\n",
       "    249,\n",
       "    1119,\n",
       "    13537,\n",
       "    240,\n",
       "    620,\n",
       "    599,\n",
       "    587,\n",
       "    512,\n",
       "    649,\n",
       "    485,\n",
       "    587,\n",
       "    562,\n",
       "    2664,\n",
       "    257],\n",
       "   [544,\n",
       "    525,\n",
       "    246,\n",
       "    928,\n",
       "    4121,\n",
       "    257,\n",
       "    1026,\n",
       "    1808,\n",
       "    257,\n",
       "    525,\n",
       "    544,\n",
       "    599,\n",
       "    249,\n",
       "    3216,\n",
       "    491,\n",
       "    481,\n",
       "    3773],\n",
       "   [10725, 2358, 3666, 267, 685, 240, 249, 1048, 267, 718, 670, 512, 257],\n",
       "   [963, 862, 240, 1784, 512, 239, 718, 640, 512, 1873, 257],\n",
       "   [249,\n",
       "    649,\n",
       "    246,\n",
       "    20394,\n",
       "    491,\n",
       "    547,\n",
       "    4090,\n",
       "    239,\n",
       "    249,\n",
       "    2958,\n",
       "    491,\n",
       "    513,\n",
       "    491,\n",
       "    246,\n",
       "    2489,\n",
       "    485,\n",
       "    15081,\n",
       "    239],\n",
       "   [685, 239, 1784, 512, 562, 481, 7832, 239],\n",
       "   [525, 544, 6977, 2417, 240, 1583, 1736, 6454, 1376, 498, 615],\n",
       "   [2229, 239, 547, 3898, 3184, 544, 3390, 239, 718, 670, 512, 257],\n",
       "   [1875,\n",
       "    267,\n",
       "    249,\n",
       "    2310,\n",
       "    256,\n",
       "    241,\n",
       "    799,\n",
       "    551,\n",
       "    889,\n",
       "    912,\n",
       "    249,\n",
       "    1048,\n",
       "    3004,\n",
       "    491,\n",
       "    547,\n",
       "    19931,\n",
       "    1890,\n",
       "    239],\n",
       "   [1141,\n",
       "    547,\n",
       "    14832,\n",
       "    249,\n",
       "    2310,\n",
       "    256,\n",
       "    241,\n",
       "    699,\n",
       "    599,\n",
       "    249,\n",
       "    256,\n",
       "    248,\n",
       "    587,\n",
       "    645,\n",
       "    249,\n",
       "    558,\n",
       "    485,\n",
       "    727,\n",
       "    246,\n",
       "    1890,\n",
       "    267],\n",
       "   [525, 636, 843, 580, 7660, 507, 8960, 267],\n",
       "   [509,\n",
       "    1304,\n",
       "    239,\n",
       "    2585,\n",
       "    3368,\n",
       "    510,\n",
       "    609,\n",
       "    488,\n",
       "    668,\n",
       "    1381,\n",
       "    1011,\n",
       "    562,\n",
       "    246,\n",
       "    2652,\n",
       "    239],\n",
       "   [645,\n",
       "    249,\n",
       "    604,\n",
       "    720,\n",
       "    1589,\n",
       "    498,\n",
       "    5408,\n",
       "    488,\n",
       "    30678,\n",
       "    484,\n",
       "    7654,\n",
       "    239,\n",
       "    984,\n",
       "    544,\n",
       "    595,\n",
       "    889,\n",
       "    267]],\n",
       "  'history': [[3569,\n",
       "    240,\n",
       "    718,\n",
       "    640,\n",
       "    512,\n",
       "    1273,\n",
       "    257,\n",
       "    249,\n",
       "    256,\n",
       "    258,\n",
       "    1381,\n",
       "    1011,\n",
       "    485,\n",
       "    587,\n",
       "    803,\n",
       "    1626,\n",
       "    17017,\n",
       "    7150,\n",
       "    485,\n",
       "    1558,\n",
       "    500,\n",
       "    3852,\n",
       "    239],\n",
       "   [512,\n",
       "    1259,\n",
       "    580,\n",
       "    963,\n",
       "    1708,\n",
       "    239,\n",
       "    5408,\n",
       "    544,\n",
       "    566,\n",
       "    498,\n",
       "    547,\n",
       "    3898,\n",
       "    31054,\n",
       "    239],\n",
       "   [249,\n",
       "    1048,\n",
       "    267,\n",
       "    562,\n",
       "    547,\n",
       "    18722,\n",
       "    249,\n",
       "    649,\n",
       "    485,\n",
       "    587,\n",
       "    2274,\n",
       "    826,\n",
       "    522,\n",
       "    803,\n",
       "    684,\n",
       "    22962,\n",
       "    239],\n",
       "   [249, 1359, 5371, 4621, 7654, 669, 249, 1048, 595, 551, 2877, 5408, 239],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    8088,\n",
       "    239,\n",
       "    669,\n",
       "    249,\n",
       "    509,\n",
       "    500,\n",
       "    1583,\n",
       "    1736,\n",
       "    249,\n",
       "    2160,\n",
       "    35716,\n",
       "    500,\n",
       "    8582,\n",
       "    48,\n",
       "    258,\n",
       "    9241,\n",
       "    267],\n",
       "   [525,\n",
       "    256,\n",
       "    252,\n",
       "    6702,\n",
       "    239,\n",
       "    587,\n",
       "    512,\n",
       "    604,\n",
       "    246,\n",
       "    3898,\n",
       "    7033,\n",
       "    522,\n",
       "    720,\n",
       "    498,\n",
       "    1803,\n",
       "    257],\n",
       "   [249,\n",
       "    587,\n",
       "    595,\n",
       "    239,\n",
       "    568,\n",
       "    249,\n",
       "    587,\n",
       "    604,\n",
       "    246,\n",
       "    3898,\n",
       "    5089,\n",
       "    1234,\n",
       "    525,\n",
       "    544,\n",
       "    589,\n",
       "    249,\n",
       "    2425,\n",
       "    22426,\n",
       "    239],\n",
       "   [599, 544, 704, 3898, 5089, 485, 2425, 257],\n",
       "   [249,\n",
       "    636,\n",
       "    604,\n",
       "    485,\n",
       "    937,\n",
       "    987,\n",
       "    8511,\n",
       "    13099,\n",
       "    239,\n",
       "    587,\n",
       "    512,\n",
       "    604,\n",
       "    775,\n",
       "    3898,\n",
       "    17794,\n",
       "    257],\n",
       "   [249, 649, 5867, 522, 32184, 488, 6821, 239],\n",
       "   [587,\n",
       "    512,\n",
       "    604,\n",
       "    1033,\n",
       "    3825,\n",
       "    562,\n",
       "    1873,\n",
       "    257,\n",
       "    249,\n",
       "    825,\n",
       "    249,\n",
       "    1048,\n",
       "    797,\n",
       "    485,\n",
       "    587,\n",
       "    803,\n",
       "    2274,\n",
       "    826,\n",
       "    239],\n",
       "   [249, 1048, 797, 485, 1832, 6210, 239, 599, 640, 512, 2274, 826, 257],\n",
       "   [249,\n",
       "    825,\n",
       "    249,\n",
       "    812,\n",
       "    759,\n",
       "    803,\n",
       "    12496,\n",
       "    239,\n",
       "    587,\n",
       "    512,\n",
       "    1359,\n",
       "    2200,\n",
       "    38963,\n",
       "    562,\n",
       "    2664,\n",
       "    257]]}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of code content shown in Medium post "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual training code and interaction code is in forked repo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting yes-and dataset for fine tuning Huggingface implementation of ConvAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../ISI_exchange/yesand_data/yes-and-data.json', 'r') as f: \n",
    "    yesand_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "all_yesands = []\n",
    "\n",
    "for k, v in yesand_data['yes-and'].items(): \n",
    "    all_yesands += v \n",
    "    \n",
    "reformatted_yesands = []\n",
    "for idx, yesand in enumerate(all_yesands): \n",
    "    instance = {\"personality\": \"\", \"utterances\": []}\n",
    "    utterance = {\"history\": [yesand['p']], \"candidates\": [all_yesands[(idx+1)%len(all_yesands)]['r'], yesand['r']]}\n",
    "    instance[\"utterances\"].append(utterance)\n",
    "    reformatted_yesands.append(instance)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'personality': '',\n",
       " 'utterances': [{'history': [\"It's good to see you!  What've you been up to?\"],\n",
       "   'candidates': ['Hey, speaking of rude, would you mind climbing out for this conversation?  Because my arms are really getting tired.',\n",
       "    'Uh, well, I was sleeping, uh, most recently, and then you guys opened the lid and then it was like a rude awakening for me.']}]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reformatted_yesands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(reformatted_yesands, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted_yesands = {'train': train, 'valid': valid}\n",
    "\n",
    "with open(\"reformatted_yesands.json\", 'w') as f: \n",
    "    json.dump(obj=reformatted_yesands, fp=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_yesands = tokenize_dataset(reformatted_yesands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "from pprint import pformat\n",
    "from argparse import ArgumentParser\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.metrics import Accuracy, Loss, MetricsLambda, RunningAverage\n",
    "from ignite.contrib.handlers import ProgressBar, PiecewiseLinear\n",
    "from ignite.contrib.handlers.tensorboard_logger import TensorboardLogger, OutputHandler, OptimizerParamsHandler\n",
    "# Migration Notes: pytorch_pretrained_bert -> pytorch_transformers. Also, there is no OpenAIAdam. OpenAIAdam -> AdamW\n",
    "from pytorch_transformers import (AdamW, OpenAIGPTDoubleHeadsModel, OpenAIGPTTokenizer,\n",
    "                                     GPT2DoubleHeadsModel, GPT2Tokenizer, WEIGHTS_NAME, CONFIG_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_added_token = tokenizer.add_special_tokens(SPECIAL_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos, eos, speaker1, speaker2 = tokenizer.convert_tokens_to_ids(list(SPECIAL_TOKENS.values())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40478, 40479, 40480, 40481)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos, eos, speaker1, speaker2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SPECIAL_TOKENS = {\"bos_token\": \"<bos>\", \n",
    "                  \"eos_token\": \"<eos>\",\n",
    "                  \"speaker1_token\": \"<speaker1>\", \n",
    "                  \"speaker2_token\": \"<speaker2>\",\n",
    "                  \"pad_token\": \"<pad>\"}\n",
    "\n",
    "MODEL_INPUTS = [\"input_ids\", \"mc_token_ids\", \"lm_labels\", \"mc_labels\", \"token_type_ids\"]\n",
    "PADDED_INPUTS = [\"input_ids\", \"lm_labels\", \"token_type_ids\"]\n",
    "\n",
    "\n",
    "def pad_dataset(dataset, padding=0):\n",
    "    \"\"\" Pad the dataset. This could be optimized by defining a Dataset class and pad only batches but this is simpler. \"\"\"\n",
    "    max_l = max(len(x) for x in dataset[\"input_ids\"])\n",
    "    for name in PADDED_INPUTS:\n",
    "        dataset[name] = [x + [padding if name != \"lm_labels\" else -1] * (max_l - len(x)) for x in dataset[name]]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def build_input_from_segments(persona, history, reply, tokenizer, lm_labels=False, with_eos=True):\n",
    "    \"\"\" Build a sequence of input from 3 segments: persona, history and last reply \"\"\"\n",
    "    bos, eos, speaker1, speaker2 = tokenizer.convert_tokens_to_ids(list(SPECIAL_TOKENS.values())[:-1])\n",
    "\n",
    "    instance = {}\n",
    "    sequence = [[bos] + list(chain(*persona))] + history + [reply + ([eos] if with_eos else [])]\n",
    "    sequence = [sequence[0]] + [[speaker2 if (len(sequence)-i) % 2 else speaker1] + s for i, s in enumerate(sequence[1:])]\n",
    "\n",
    "    instance[\"input_ids\"] = list(chain(*sequence))\n",
    "    instance[\"token_type_ids\"] = [speaker2 if i % 2 else speaker1 for i, s in enumerate(sequence) for _ in s]\n",
    "    instance[\"mc_token_ids\"] = len(instance[\"input_ids\"]) - 1\n",
    "    instance[\"lm_labels\"] = [-1] * len(instance[\"input_ids\"])\n",
    "    if lm_labels:\n",
    "        instance[\"lm_labels\"] = ([-1] * sum(len(s) for s in sequence[:-1])) + [-1] + sequence[-1][1:]\n",
    "    return instance, sequence\n",
    "\n",
    "\n",
    "def get_data_loaders(tokenizer):\n",
    "    \"\"\" Prepare the dataset for training and evaluation \"\"\"\n",
    "#     dataset_cache = './dataset_cache'\n",
    "#     dataset_cache = dataset_cache + '_' + type(tokenizer).__name__\n",
    "\n",
    "#     if dataset_cache and os.path.isfile(dataset_cache):\n",
    "#         personachat = torch.load(dataset_cache)\n",
    "\n",
    "    personachat = tokenized_yesands\n",
    "\n",
    "    import pdb; pdb.set_trace()\n",
    "    print(\"Build inputs and labels\")\n",
    "    datasets = {\"train\": defaultdict(list), \"valid\": defaultdict(list)}\n",
    "    for dataset_name, dataset in personachat.items():\n",
    "        num_candidates = len(dataset[0][\"utterances\"][0][\"candidates\"])\n",
    "        if 2 > 0 and dataset_name == 'train':\n",
    "            num_candidates = min(2, num_candidates)\n",
    "        for dialog in dataset:\n",
    "            persona = dialog[\"personality\"].copy()\n",
    "            for _ in range(1):\n",
    "                for utterance in dialog[\"utterances\"]:\n",
    "                    history = utterance[\"history\"][-(2*2+1):]\n",
    "                    for j, candidate in enumerate(utterance[\"candidates\"][-num_candidates:]):\n",
    "                        lm_labels = bool(j == num_candidates-1)\n",
    "                        instance, _ = build_input_from_segments(persona, history, candidate, tokenizer, lm_labels)\n",
    "                        for input_name, input_array in instance.items():\n",
    "                            datasets[dataset_name][input_name].append(input_array)\n",
    "                    datasets[dataset_name][\"mc_labels\"].append(num_candidates - 1)\n",
    "                    datasets[dataset_name][\"n_candidates\"] = num_candidates\n",
    "                persona = [persona[-1]] + persona[:-1]  # permuted personalities\n",
    "                \n",
    "            break \n",
    "#         break \n",
    "\n",
    "    print(\"Pad inputs and convert to Tensor\")\n",
    "    tensor_datasets = {\"train\": [], \"valid\": []}\n",
    "    for dataset_name, dataset in datasets.items():\n",
    "        dataset = pad_dataset(dataset, padding=tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS[\"pad_token\"]))\n",
    "        for input_name in MODEL_INPUTS:\n",
    "            tensor = torch.tensor(dataset[input_name])\n",
    "            if input_name != \"mc_labels\":\n",
    "                tensor = tensor.view((-1, datasets[dataset_name][\"n_candidates\"]) + tensor.shape[1:])\n",
    "            tensor_datasets[dataset_name].append(tensor)\n",
    "            \n",
    "#         break\n",
    "\n",
    "    print(\"Build train and validation dataloaders\")\n",
    "    train_dataset, valid_dataset = TensorDataset(*tensor_datasets[\"train\"]), TensorDataset(*tensor_datasets[\"valid\"])\n",
    "    train_sampler = None\n",
    "    valid_sampler = None\n",
    "    train_loader = DataLoader(train_dataset, sampler=train_sampler, batch_size=4, shuffle=(not False))\n",
    "    valid_loader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=4, shuffle=False)\n",
    "\n",
    "    print(\"Train dataset (Batch, Candidates, Seq length): {}\".format(train_dataset.tensors[0].shape))\n",
    "    print(\"Valid dataset (Batch, Candidates, Seq length): {}\".format(valid_dataset.tensors[0].shape))\n",
    "    \n",
    "    return train_loader, valid_loader, train_sampler, valid_sampler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-88-7cbd7b890c89>(48)get_data_loaders()\n",
      "-> print(\"Build inputs and labels\")\n",
      "(Pdb) n\n",
      "Build inputs and labels\n",
      "> <ipython-input-88-7cbd7b890c89>(49)get_data_loaders()\n",
      "-> datasets = {\"train\": defaultdict(list), \"valid\": defaultdict(list)}\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(50)get_data_loaders()\n",
      "-> for dataset_name, dataset in personachat.items():\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(51)get_data_loaders()\n",
      "-> num_candidates = len(dataset[0][\"utterances\"][0][\"candidates\"])\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(52)get_data_loaders()\n",
      "-> if 2 > 0 and dataset_name == 'train':\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(53)get_data_loaders()\n",
      "-> num_candidates = min(2, num_candidates)\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(54)get_data_loaders()\n",
      "-> for dialog in dataset:\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(55)get_data_loaders()\n",
      "-> persona = dialog[\"personality\"].copy()\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(56)get_data_loaders()\n",
      "-> for _ in range(1):\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(57)get_data_loaders()\n",
      "-> for utterance in dialog[\"utterances\"]:\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(58)get_data_loaders()\n",
      "-> history = utterance[\"history\"][-(2*2+1):]\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(59)get_data_loaders()\n",
      "-> for j, candidate in enumerate(utterance[\"candidates\"][-num_candidates:]):\n",
      "(Pdb) history\n",
      "[[4360, 239, 20, 1878, 486, 852, 240, 704, 5553, 544, 620, 870, 239, 606, 640, 8172, 589, 7021, 498, 40087, 239, 989, 640, 620, 4182, 670, 599, 600, 1344, 617, 1392, 498, 1187, 267]]\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(60)get_data_loaders()\n",
      "-> lm_labels = bool(j == num_candidates-1)\n",
      "(Pdb) history\n",
      "[[4360, 239, 20, 1878, 486, 852, 240, 704, 5553, 544, 620, 870, 239, 606, 640, 8172, 589, 7021, 498, 40087, 239, 989, 640, 620, 4182, 670, 599, 600, 1344, 617, 1392, 498, 1187, 267]]\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(61)get_data_loaders()\n",
      "-> instance, _ = build_input_from_segments(persona, history, candidate, tokenizer, lm_labels)\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(62)get_data_loaders()\n",
      "-> for input_name, input_array in instance.items():\n",
      "(Pdb) instance\n",
      "{'input_ids': [40478, 40481, 4360, 239, 20, 1878, 486, 852, 240, 704, 5553, 544, 620, 870, 239, 606, 640, 8172, 589, 7021, 498, 40087, 239, 989, 640, 620, 4182, 670, 599, 600, 1344, 617, 1392, 498, 1187, 267, 40480, 525, 256, 252, 246, 16273, 865, 650, 2399, 498, 1563, 525, 249, 558, 2318, 620, 525, 989, 635, 1623, 718, 6049, 547, 2044, 12008, 239, 40479], 'token_type_ids': [40480, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480], 'mc_token_ids': 62, 'lm_labels': [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}\n",
      "(Pdb) tokenizer.convert_ids_to_tokens(instance['input_ids'])\n",
      "['<bos>', '<speaker2>', 'mr</w>', '.</w>', 'm', 'iti', 'er', 'ry</w>', ',</w>', 'your</w>', 'advice</w>', 'is</w>', 'so</w>', 'good</w>', '.</w>', 'we</w>', 'are</w>', 'selling</w>', 'all</w>', 'sorts</w>', 'of</w>', 'concessions</w>', '.</w>', 'people</w>', 'are</w>', 'so</w>', 'curious</w>', 'about</w>', 'what</w>', 'they</w>', 'hear</w>', 'from</w>', 'word</w>', 'of</w>', 'mouth</w>', '!</w>', '<speaker1>', 'that</w>', \"'</w>\", 's</w>', 'a</w>', 'gob', 'bl', 'ers</w>', 'piece</w>', 'of</w>', 'skin</w>', 'that</w>', 'i</w>', 'had</w>', 'added</w>', 'so</w>', 'that</w>', 'people</w>', 'could</w>', 'understand</w>', 'how</w>', 'delicious</w>', 'my</w>', 'food</w>', 'tastes</w>', '.</w>', '<eos>']\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(63)get_data_loaders()\n",
      "-> datasets[dataset_name][input_name].append(input_array)\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(62)get_data_loaders()\n",
      "-> for input_name, input_array in instance.items():\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(63)get_data_loaders()\n",
      "-> datasets[dataset_name][input_name].append(input_array)\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(62)get_data_loaders()\n",
      "-> for input_name, input_array in instance.items():\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(63)get_data_loaders()\n",
      "-> datasets[dataset_name][input_name].append(input_array)\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(62)get_data_loaders()\n",
      "-> for input_name, input_array in instance.items():\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(63)get_data_loaders()\n",
      "-> datasets[dataset_name][input_name].append(input_array)\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(62)get_data_loaders()\n",
      "-> for input_name, input_array in instance.items():\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(59)get_data_loaders()\n",
      "-> for j, candidate in enumerate(utterance[\"candidates\"][-num_candidates:]):\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(60)get_data_loaders()\n",
      "-> lm_labels = bool(j == num_candidates-1)\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(61)get_data_loaders()\n",
      "-> instance, _ = build_input_from_segments(persona, history, candidate, tokenizer, lm_labels)\n",
      "(Pdb) n\n",
      "> <ipython-input-88-7cbd7b890c89>(62)get_data_loaders()\n",
      "-> for input_name, input_array in instance.items():\n",
      "(Pdb) instance\n",
      "{'input_ids': [40478, 40481, 4360, 239, 20, 1878, 486, 852, 240, 704, 5553, 544, 620, 870, 239, 606, 640, 8172, 589, 7021, 498, 40087, 239, 989, 640, 620, 4182, 670, 599, 600, 1344, 617, 1392, 498, 1187, 267, 40480, 2310, 256, 241, 1784, 510, 239, 1784, 704, 37670, 239, 600, 256, 716, 531, 2283, 1250, 498, 1099, 4824, 239, 40479], 'token_type_ids': [40480, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480], 'mc_token_ids': 57, 'lm_labels': [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2310, 256, 241, 1784, 510, 239, 1784, 704, 37670, 239, 600, 256, 716, 531, 2283, 1250, 498, 1099, 4824, 239, 40479]}\n",
      "(Pdb) quit()\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-09cbfff49317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_data_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-7cbd7b890c89>\u001b[0m in \u001b[0;36mget_data_loaders\u001b[0;34m(tokenizer)\u001b[0m\n\u001b[1;32m     60\u001b[0m                         \u001b[0mlm_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_candidates\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                         \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_input_from_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersona\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_array\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                             \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mc_labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_candidates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-7cbd7b890c89>\u001b[0m in \u001b[0;36mget_data_loaders\u001b[0;34m(tokenizer)\u001b[0m\n\u001b[1;32m     60\u001b[0m                         \u001b[0mlm_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_candidates\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                         \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_input_from_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersona\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_array\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                             \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mc_labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_candidates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ased/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ased/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_data_loaders(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
